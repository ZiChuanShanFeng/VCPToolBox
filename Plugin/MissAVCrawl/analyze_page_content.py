#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±å…¥åˆ†æé¡µé¢å†…å®¹ï¼ŒæŸ¥æ‰¾é¢„è§ˆè§†é¢‘çš„æ„é€ é€»è¾‘
"""

import sys
import re
import json
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å—
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from missav_api_core import MissAVCrawler

def analyze_page_content(url):
    """æ·±å…¥åˆ†æé¡µé¢å†…å®¹"""
    print(f"ğŸ” æ·±å…¥åˆ†æé¡µé¢å†…å®¹: {url}")
    print("=" * 80)
    
    # è·å–é¡µé¢å†…å®¹
    crawler = MissAVCrawler()
    extractor = crawler.client.info_extractor
    content = extractor.core.fetch(url)
    
    if not content:
        print("âŒ æ— æ³•è·å–é¡µé¢å†…å®¹")
        return
    
    print(f"âœ… é¡µé¢å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    print("-" * 80)
    
    # 1. æŸ¥æ‰¾cdnUrlå‡½æ•°å®šä¹‰
    print("ğŸ“¥ æ­¥éª¤1: æŸ¥æ‰¾cdnUrlå‡½æ•°å®šä¹‰")
    cdn_patterns = [
        r'function\s+cdnUrl\s*\([^)]*\)\s*{[^}]+}',
        r'cdnUrl\s*:\s*function\s*\([^)]*\)\s*{[^}]+}',
        r'const\s+cdnUrl\s*=\s*[^;]+;',
        r'var\s+cdnUrl\s*=\s*[^;]+;',
        r'let\s+cdnUrl\s*=\s*[^;]+;',
    ]
    
    for i, pattern in enumerate(cdn_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
        if matches:
            print(f"  CDNæ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches:
                clean_match = match.replace('\n', ' ').replace('\r', '')
                if len(clean_match) > 200:
                    clean_match = clean_match[:200] + "..."
                print(f"    - {clean_match}")
            print()
    
    # 2. æŸ¥æ‰¾dvd_idçš„å€¼
    print("ğŸ“¥ æ­¥éª¤2: æŸ¥æ‰¾dvd_idçš„å€¼")
    dvd_id_patterns = [
        r'"dvd_id"\s*:\s*"?([^",\s]+)"?',
        r'dvd_id\s*:\s*"?([^",\s]+)"?',
        r'data-dvd-id\s*=\s*["\']([^"\']+)["\']',
        r'var\s+dvd_id\s*=\s*["\']([^"\']+)["\']',
        r'let\s+dvd_id\s*=\s*["\']([^"\']+)["\']',
        r'const\s+dvd_id\s*=\s*["\']([^"\']+)["\']',
    ]
    
    found_dvd_ids = []
    for i, pattern in enumerate(dvd_id_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            print(f"  DVD_IDæ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches[:5]:
                print(f"    - {match}")
                if match not in found_dvd_ids:
                    found_dvd_ids.append(match)
            if len(matches) > 5:
                print(f"    ... è¿˜æœ‰ {len(matches) - 5} ä¸ª")
            print()
    
    # 3. æŸ¥æ‰¾CDNåŸºç¡€URL
    print("ğŸ“¥ æ­¥éª¤3: æŸ¥æ‰¾CDNåŸºç¡€URL")
    cdn_base_patterns = [
        r'https://[^"\s]*doppiocdn[^"\s]*',
        r'https://media[^"\s]*\.net[^"\s]*',
        r'"cdn[^"]*":\s*"([^"]+)"',
        r'baseUrl\s*:\s*["\']([^"\']+)["\']',
        r'cdnBase\s*:\s*["\']([^"\']+)["\']',
    ]
    
    found_cdn_urls = []
    for i, pattern in enumerate(cdn_base_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            print(f"  CDN_BASEæ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches[:3]:
                print(f"    - {match}")
                if match not in found_cdn_urls:
                    found_cdn_urls.append(match)
            if len(matches) > 3:
                print(f"    ... è¿˜æœ‰ {len(matches) - 3} ä¸ª")
            print()
    
    # 4. æŸ¥æ‰¾å®Œæ•´çš„è§†é¢‘é…ç½®å¯¹è±¡
    print("ğŸ“¥ æ­¥éª¤4: æŸ¥æ‰¾è§†é¢‘é…ç½®å¯¹è±¡")
    config_patterns = [
        r'window\.__INITIAL_STATE__\s*=\s*({.+?});',
        r'window\.videoData\s*=\s*({.+?});',
        r'var\s+videoConfig\s*=\s*({.+?});',
        r'const\s+videoConfig\s*=\s*({.+?});',
        r'data:\s*({[^}]*dvd_id[^}]*})',
    ]
    
    for i, pattern in enumerate(config_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
        if matches:
            print(f"  CONFIGæ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches[:1]:  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªï¼Œå› ä¸ºå¯èƒ½å¾ˆé•¿
                try:
                    # å°è¯•è§£æJSON
                    if match.strip().startswith('{'):
                        config_data = json.loads(match)
                        print(f"    - æˆåŠŸè§£æJSONé…ç½®ï¼ŒåŒ…å« {len(config_data)} ä¸ªé”®")
                        
                        # æŸ¥æ‰¾ç›¸å…³çš„é”®
                        relevant_keys = []
                        for key in config_data.keys():
                            if any(keyword in key.lower() for keyword in ['video', 'dvd', 'id', 'preview', 'media']):
                                relevant_keys.append(key)
                        
                        if relevant_keys:
                            print(f"      ç›¸å…³é”®: {relevant_keys}")
                            for key in relevant_keys[:3]:
                                print(f"        {key}: {config_data[key]}")
                    else:
                        clean_match = match.replace('\n', ' ')[:200] + "..."
                        print(f"    - {clean_match}")
                except json.JSONDecodeError:
                    clean_match = match.replace('\n', ' ')[:200] + "..."
                    print(f"    - {clean_match}")
            print()
    
    # 5. æŸ¥æ‰¾å…·ä½“çš„é¢„è§ˆè§†é¢‘URLæ¨¡å¼
    print("ğŸ“¥ æ­¥éª¤5: æŸ¥æ‰¾å…·ä½“çš„é¢„è§ˆè§†é¢‘URL")
    
    # åŸºäºæ‰¾åˆ°çš„ä¿¡æ¯æ„é€ é¢„è§ˆè§†é¢‘URL
    if found_dvd_ids and found_cdn_urls:
        print("åŸºäºæ‰¾åˆ°çš„ä¿¡æ¯æ„é€ é¢„è§ˆè§†é¢‘URL:")
        for dvd_id in found_dvd_ids[:3]:
            for cdn_url in found_cdn_urls[:2]:
                # æ¸…ç†CDN URL
                clean_cdn = cdn_url.rstrip('/')
                
                # æ„é€ å¯èƒ½çš„é¢„è§ˆè§†é¢‘URL
                possible_urls = [
                    f"{clean_cdn}/{dvd_id}/preview.mp4",
                    f"{clean_cdn}/b-hls-06/{dvd_id}/{dvd_id}_preview.mp4",
                    f"{clean_cdn}/preview/{dvd_id}.mp4",
                ]
                
                for url in possible_urls:
                    print(f"  - {url}")
        print()
    
    # 6. æŸ¥æ‰¾é¡µé¢ä¸­çš„å®é™…é¢„è§ˆè§†é¢‘å…ƒç´ 
    print("ğŸ“¥ æ­¥éª¤6: æŸ¥æ‰¾é¢„è§ˆè§†é¢‘HTMLå…ƒç´ ")
    video_element_patterns = [
        r'<video[^>]*preview[^>]*>',
        r'<[^>]*data-src[^>]*preview[^>]*>',
        r'<[^>]*onmouseover[^>]*video[^>]*>',
        r'<[^>]*hover[^>]*video[^>]*>',
    ]
    
    for i, pattern in enumerate(video_element_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
        if matches:
            print(f"  VIDEOå…ƒç´ æ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches[:2]:
                clean_match = match.replace('\n', ' ')
                if len(clean_match) > 150:
                    clean_match = clean_match[:150] + "..."
                print(f"    - {clean_match}")
            print()
    
    return found_dvd_ids, found_cdn_urls

def test_constructed_urls(dvd_ids, cdn_urls):
    """æµ‹è¯•æ„é€ çš„é¢„è§ˆè§†é¢‘URL"""
    print("\nğŸ“¥ æµ‹è¯•æ„é€ çš„é¢„è§ˆè§†é¢‘URL")
    print("-" * 80)
    
    import requests
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://missav.ws/',
        'Accept': 'video/mp4,video/*,*/*;q=0.9',
    }
    
    test_count = 0
    success_count = 0
    
    for dvd_id in dvd_ids[:2]:  # åªæµ‹è¯•å‰2ä¸ªID
        for cdn_url in cdn_urls[:2]:  # åªæµ‹è¯•å‰2ä¸ªCDN
            clean_cdn = cdn_url.rstrip('/')
            
            test_urls = [
                f"{clean_cdn}/{dvd_id}/preview.mp4",
                f"{clean_cdn}/b-hls-06/{dvd_id}/{dvd_id}_preview.mp4",
                f"{clean_cdn}/preview/{dvd_id}.mp4",
            ]
            
            for test_url in test_urls:
                if test_count >= 10:  # é™åˆ¶æµ‹è¯•æ•°é‡
                    break
                
                test_count += 1
                print(f"æµ‹è¯• {test_count}: {test_url}")
                
                try:
                    response = requests.head(test_url, headers=headers, timeout=10)
                    print(f"  çŠ¶æ€ç : {response.status_code}")
                    
                    if response.status_code == 200:
                        content_type = response.headers.get('Content-Type', '')
                        content_length = response.headers.get('Content-Length', '')
                        print(f"  å†…å®¹ç±»å‹: {content_type}")
                        if content_length:
                            print(f"  æ–‡ä»¶å¤§å°: {content_length} å­—èŠ‚")
                        print("  âœ… æˆåŠŸæ‰¾åˆ°é¢„è§ˆè§†é¢‘!")
                        success_count += 1
                    elif response.status_code == 403:
                        print("  âš ï¸  403 Forbidden - å¯èƒ½éœ€è¦ç‰¹æ®Šçš„è®¤è¯æˆ–Referer")
                    else:
                        print("  âŒ ä¸å¯è®¿é—®")
                        
                except Exception as e:
                    print(f"  âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
                
                print()
    
    print(f"æµ‹è¯•æ€»ç»“: {success_count}/{test_count} ä¸ªURLå¯è®¿é—®")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ·±å…¥åˆ†æé¡µé¢å†…å®¹ï¼ŒæŸ¥æ‰¾é¢„è§ˆè§†é¢‘æ„é€ é€»è¾‘")
    print("=" * 80)
    
    # æµ‹è¯•URL
    test_url = "https://missav.ws/dm44/jul-875"
    
    # åˆ†æé¡µé¢å†…å®¹
    dvd_ids, cdn_urls = analyze_page_content(test_url)
    
    # æµ‹è¯•æ„é€ çš„URL
    if dvd_ids and cdn_urls:
        test_constructed_urls(dvd_ids, cdn_urls)
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ åˆ†æå®Œæˆ")
    print(f"æ‰¾åˆ° {len(dvd_ids)} ä¸ªDVD ID")
    print(f"æ‰¾åˆ° {len(cdn_urls)} ä¸ªCDN URL")

if __name__ == "__main__":
    main()