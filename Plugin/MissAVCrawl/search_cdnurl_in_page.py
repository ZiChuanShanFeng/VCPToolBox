#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ¥åœ¨é¡µé¢å†…å®¹ä¸­æœç´¢cdnUrl
"""

import sys
import re
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å—
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from missav_api_core import MissAVCrawler

def search_cdnurl_in_page(url):
    """ç›´æ¥åœ¨é¡µé¢å†…å®¹ä¸­æœç´¢cdnUrl"""
    print(f"ğŸ” åœ¨é¡µé¢å†…å®¹ä¸­æœç´¢cdnUrl: {url}")
    print("=" * 80)
    
    # è·å–é¡µé¢å†…å®¹
    crawler = MissAVCrawler()
    extractor = crawler.client.info_extractor
    content = extractor.core.fetch(url)
    
    if not content:
        print("âŒ æ— æ³•è·å–é¡µé¢å†…å®¹")
        return
    
    print(f"âœ… é¡µé¢å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    print("-" * 80)
    
    # æœç´¢cdnUrlçš„æ‰€æœ‰å‡ºç°
    print("ğŸ“¥ æœç´¢cdnUrlçš„æ‰€æœ‰å‡ºç°:")
    
    # ä½¿ç”¨ä¸åŒçš„æœç´¢æ¨¡å¼
    search_patterns = [
        r'cdnUrl',
        r'cdn_url',
        r'cdnURL',
        r'[Cc]dn[Uu]rl',
    ]
    
    all_matches = []
    
    for pattern in search_patterns:
        matches = list(re.finditer(pattern, content, re.IGNORECASE))
        if matches:
            print(f"æ¨¡å¼ '{pattern}': æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            all_matches.extend(matches)
    
    # å»é‡å¹¶æŒ‰ä½ç½®æ’åº
    unique_positions = set()
    unique_matches = []
    
    for match in all_matches:
        if match.start() not in unique_positions:
            unique_positions.add(match.start())
            unique_matches.append(match)
    
    unique_matches.sort(key=lambda x: x.start())
    
    print(f"\næ€»å…±æ‰¾åˆ° {len(unique_matches)} ä¸ªå”¯ä¸€çš„cdnUrlåŒ¹é…")
    
    # æ˜¾ç¤ºæ¯ä¸ªåŒ¹é…åŠå…¶ä¸Šä¸‹æ–‡
    for i, match in enumerate(unique_matches, 1):
        start_pos = match.start()
        end_pos = match.end()
        
        # è·å–ä¸Šä¸‹æ–‡ï¼ˆå‰åå„100ä¸ªå­—ç¬¦ï¼‰
        context_start = max(0, start_pos - 100)
        context_end = min(len(content), end_pos + 100)
        
        context = content[context_start:context_end]
        
        # æ¸…ç†ä¸Šä¸‹æ–‡ï¼Œç§»é™¤æ¢è¡Œç¬¦
        clean_context = context.replace('\n', ' ').replace('\r', ' ')
        
        print(f"\nåŒ¹é… {i} (ä½ç½® {start_pos}-{end_pos}):")
        print(f"  ä¸Šä¸‹æ–‡: ...{clean_context}...")
        
        # å°è¯•æå–æ›´å¤§çš„ä¸Šä¸‹æ–‡æ¥æ‰¾åˆ°å‡½æ•°å®šä¹‰
        if 'function' in context.lower() or '=>' in context or '=' in context:
            # æ‰©å±•ä¸Šä¸‹æ–‡æ¥æŸ¥æ‰¾å®Œæ•´çš„å‡½æ•°å®šä¹‰
            extended_start = max(0, start_pos - 500)
            extended_end = min(len(content), end_pos + 500)
            extended_context = content[extended_start:extended_end]
            
            # æŸ¥æ‰¾å‡½æ•°å®šä¹‰æ¨¡å¼
            function_patterns = [
                r'function\s+[^(]*cdnUrl[^(]*\([^)]*\)\s*{[^}]*}',
                r'[^=]*cdnUrl[^=]*=\s*function[^{]*{[^}]*}',
                r'[^=]*cdnUrl[^=]*=\s*[^;]+',
                r'const\s+[^=]*cdnUrl[^=]*=\s*[^;]+',
                r'var\s+[^=]*cdnUrl[^=]*=\s*[^;]+',
                r'let\s+[^=]*cdnUrl[^=]*=\s*[^;]+',
            ]
            
            for pattern in function_patterns:
                func_matches = re.findall(pattern, extended_context, re.IGNORECASE | re.DOTALL)
                if func_matches:
                    print(f"  å¯èƒ½çš„å‡½æ•°å®šä¹‰:")
                    for func_match in func_matches:
                        clean_func = func_match.replace('\n', ' ').replace('\r', '')
                        if len(clean_func) > 200:
                            clean_func = clean_func[:200] + "..."
                        print(f"    {clean_func}")
    
    # ç‰¹åˆ«æŸ¥æ‰¾Alpine.jsçš„æ•°æ®ç»‘å®š
    print(f"\nğŸ“¥ æŸ¥æ‰¾Alpine.jsæ•°æ®ç»‘å®šä¸­çš„cdnUrl:")
    
    # æŸ¥æ‰¾x-dataå±æ€§ä¸­çš„cdnUrl
    alpine_pattern = r'x-data\s*=\s*["\'][^"\']*cdnUrl[^"\']*["\']'
    alpine_matches = re.findall(alpine_pattern, content, re.IGNORECASE | re.DOTALL)
    
    if alpine_matches:
        print(f"æ‰¾åˆ° {len(alpine_matches)} ä¸ªAlpine.jsæ•°æ®ç»‘å®š:")
        for match in alpine_matches:
            clean_match = match.replace('\n', ' ')
            print(f"  - {clean_match}")
    
    # æŸ¥æ‰¾:data-srcå±æ€§ä¸­çš„cdnUrl
    data_src_pattern = r':data-src\s*=\s*["\'][^"\']*cdnUrl[^"\']*["\']'
    data_src_matches = re.findall(data_src_pattern, content, re.IGNORECASE | re.DOTALL)
    
    if data_src_matches:
        print(f"æ‰¾åˆ° {len(data_src_matches)} ä¸ª:data-srcç»‘å®š:")
        for match in data_src_matches:
            clean_match = match.replace('\n', ' ')
            print(f"  - {clean_match}")
    
    # æŸ¥æ‰¾æ¨¡æ¿å­—ç¬¦ä¸²ä¸­çš„cdnUrl
    template_pattern = r'`[^`]*cdnUrl[^`]*`'
    template_matches = re.findall(template_pattern, content, re.IGNORECASE | re.DOTALL)
    
    if template_matches:
        print(f"æ‰¾åˆ° {len(template_matches)} ä¸ªæ¨¡æ¿å­—ç¬¦ä¸²:")
        for match in template_matches:
            clean_match = match.replace('\n', ' ')
            print(f"  - {clean_match}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ç›´æ¥åœ¨é¡µé¢å†…å®¹ä¸­æœç´¢cdnUrl")
    print("=" * 80)
    
    # æµ‹è¯•URL
    test_url = "https://missav.ws/dm44/jul-875"
    
    # æœç´¢cdnUrl
    search_cdnurl_in_page(test_url)
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ æœç´¢å®Œæˆ")

if __name__ == "__main__":
    main()