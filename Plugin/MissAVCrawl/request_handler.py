#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MissAV è¯·æ±‚å¤„ç†å™¨ - ä½¿ç”¨æ¨¡å—åŒ–ç»“æ„
"""

import sys
import json
import traceback
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å—
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# å¯¼å…¥æ¨¡å—åŒ–ç»„ä»¶
from missav_api_core import MissAVCrawler


def process_request(request_data: dict) -> dict:
    """å¤„ç†è¯·æ±‚"""
    try:
        command = request_data.get('command', '').strip()
        
        if not command:
            return {
                "status": "error",
                "error": "ç¼ºå°‘ command å‚æ•°"
            }
        
        # åˆå§‹åŒ–çˆ¬è™«
        crawler = MissAVCrawler()
        
        if command == "GetVideoInfo":
            url = request_data.get('url', '') or ''
            if isinstance(url, str):
                url = url.strip()
            else:
                url = str(url).strip() if url is not None else ''
            if not url:
                return {
                    "status": "error",
                    "error": "ç¼ºå°‘ url å‚æ•°"
                }
            
            # ä½¿ç”¨å¢å¼ºä¿¡æ¯æå–åŠŸèƒ½ï¼ˆä¼˜å…ˆå®æ—¶æŸ¥æ‰¾ï¼Œå¤±è´¥æ—¶ä½¿ç”¨ç¼“å­˜ï¼‰
            if hasattr(crawler, 'client') and hasattr(crawler.client, 'get_enhanced_video_info'):
                result = crawler.client.get_enhanced_video_info(url, use_cache=True)
                
                if result.get("success"):
                    # ä½¿ç”¨å¢å¼ºæ ¼å¼åŒ–å™¨
                    if hasattr(crawler.client.info_extractor, 'format_info_response'):
                        response_text = crawler.client.info_extractor.format_info_response(result)
                    else:
                        # å›é€€åˆ°åŸºç¡€æ ¼å¼åŒ–
                        info = result.get("info", result)
                        response_text = f"""### MissAV å¢å¼ºè§†é¢‘ä¿¡æ¯ ###

**æ¨™é¡Œ**: {info.get('title', 'æœªçŸ¥')}
**ç•ªè™Ÿ**: {info.get('video_code', 'æœªçŸ¥')}
**ç™¼è¡Œæ—¥æœŸ**: {info.get('release_date', info.get('publish_date', 'æœªçŸ¥'))}
**æ™‚é•·**: {info.get('duration', 'æœªçŸ¥')}
**å¥³å„ª**: {', '.join(info.get('actresses', []))}
**é¡å‹**: {', '.join(info.get('types', []))}
**ç³»åˆ—**: {info.get('series', 'æœªçŸ¥')}
**ç™¼è¡Œå•†**: {info.get('publisher', 'æœªçŸ¥')}
**æ¨™ç±¤**: {', '.join(info.get('tags', []))}
**å°é¢åœ–ç‰‡**: {info.get('main_cover', info.get('thumbnail', 'æœªçŸ¥'))}
**M3U8æ’­æ”¾åˆ—è¡¨**: {info.get('m3u8_url', 'æœªçŸ¥')}
**åŸå§‹URL**: {url}

å¢å¼ºè§†é¢‘ä¿¡æ¯è·å–æˆåŠŸï¼"""
                    
                    return {
                        "status": "success",
                        "result": response_text
                    }
                else:
                    return {
                        "status": "error",
                        "error": result.get("error", "è·å–å¢å¼ºè§†é¢‘ä¿¡æ¯å¤±è´¥")
                    }
            else:
                # å›é€€åˆ°åŸºç¡€ä¿¡æ¯è·å–
                result = crawler.get_video_info(url)
                
                if result["success"]:
                    info = result["info"]
                    response_text = f"""### MissAV åŸºç¡€è§†é¢‘ä¿¡æ¯ ###

**æ ‡é¢˜**: {info['title']}
**è§†é¢‘ä»£ç **: {info['video_code']}
**å‘å¸ƒæ—¥æœŸ**: {info['publish_date']}
**ç¼©ç•¥å›¾**: {info['thumbnail']}
**M3U8 URL**: {info['m3u8_url']}
**åŸå§‹URL**: {info['url']}

åŸºç¡€è§†é¢‘ä¿¡æ¯è·å–æˆåŠŸï¼"""
                    
                    return {
                        "status": "success",
                        "result": response_text
                    }
                else:
                    return {
                        "status": "error",
                        "error": result["error"]
                    }
        
        elif command == "DownloadVideo":
            url = request_data.get('url', '') or ''
            if isinstance(url, str):
                url = url.strip()
            else:
                url = str(url).strip() if url is not None else ''
            if not url:
                return {
                    "status": "error",
                    "error": "ç¼ºå°‘ url å‚æ•°"
                }
            
            quality = request_data.get('quality', '').strip()
            download_dir = request_data.get('download_dir', '').strip()
            downloader = request_data.get('downloader', '').strip()
            
            result = crawler.download_video(
                url=url,
                quality=quality if quality else None,
                download_dir=download_dir if download_dir else None,
                downloader=downloader if downloader else None
            )
            
            if result["success"]:
                info = result["video_info"]
                response_text = f"""### MissAV è§†é¢‘ä¸‹è½½å®Œæˆ ###

æ ‡é¢˜: {info['title']}
è§†é¢‘ä»£ç : {info['video_code']}
å‘å¸ƒæ—¥æœŸ: {info['publish_date']}
æ–‡ä»¶è·¯å¾„: {result['file_path']}
ä¸‹è½½ç›®å½•: {result['download_dir']}
è§†é¢‘è´¨é‡: {result['quality']}

è§†é¢‘ä¸‹è½½æˆåŠŸï¼æ–‡ä»¶å·²ä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚"""
                
                return {
                    "status": "success",
                    "result": response_text
                }
            else:
                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                if "video_info" in result:
                    info = result["video_info"]
                    error_msg += f"\nè§†é¢‘ä¿¡æ¯: {info['title']} ({info['video_code']})"
                
                return {
                    "status": "error",
                    "error": error_msg
                }
        
        elif command == "SearchVideos":
            keyword = request_data.get('keyword', '') or ''
            if isinstance(keyword, str):
                keyword = keyword.strip()
            else:
                keyword = str(keyword).strip() if keyword is not None else ''
            if not keyword:
                return {
                    "status": "error",
                    "error": "ç¼ºå°‘ keyword å‚æ•°"
                }
            
            # å¤„ç†é¡µç å‚æ•°
            page = request_data.get('page', 1)
            try:
                page = int(page) if page else 1
                if page < 1:
                    page = 1
            except (ValueError, TypeError):
                page = 1
            
            # å¤„ç†æ’åºå‚æ•°
            sort = request_data.get('sort', '').strip()
            valid_sorts = ['saved', 'today_views', 'weekly_views', 'monthly_views', 'views', 'updated', 'released_at']
            if sort and sort not in valid_sorts:
                sort = None
            
            # å¤„ç†è¿‡æ»¤å™¨å‚æ•°
            filter_type = request_data.get('filter', '').strip()
            valid_filters = ['all', 'single', 'japanese', 'uncensored_leak', 'uncensored', 'chinese_subtitle']
            if filter_type and filter_type not in valid_filters:
                filter_type = None
            
            # å¤„ç†å°é¢å›¾ç‰‡å‚æ•°
            include_cover = request_data.get('include_cover', True)
            if isinstance(include_cover, str):
                include_cover = include_cover.lower() in ['true', '1', 'yes', 'on']
            
            # å¤„ç†æ ‡é¢˜å‚æ•°
            include_title = request_data.get('include_title', True)
            if isinstance(include_title, str):
                include_title = include_title.lower() in ['true', '1', 'yes', 'on']
            
            # å¤„ç†æœ€å¤§ç»“æœæ•°å‚æ•°
            max_results = request_data.get('max_results', 20)
            try:
                max_results = int(max_results) if max_results else 20
                if max_results < 1:
                    max_results = 20
                elif max_results > 100:
                    max_results = 100
            except (ValueError, TypeError):
                max_results = 20
            
            # å¤„ç†æœ€å¤§é¡µæ•°å‚æ•°
            max_pages = request_data.get('max_pages', 1)
            try:
                max_pages = int(max_pages) if max_pages else 1
                if max_pages < 1:
                    max_pages = 1
                elif max_pages > 10:
                    max_pages = 10
            except (ValueError, TypeError):
                max_pages = 1
            
            # å¤„ç†å¢å¼ºä¿¡æ¯å‚æ•°
            enhanced_info = request_data.get('enhanced_info', False)
            if isinstance(enhanced_info, str):
                enhanced_info = enhanced_info.lower() in ['true', '1', 'yes', 'on']
            
            # ä½¿ç”¨å¢å¼ºæœç´¢åŠŸèƒ½
            if hasattr(crawler, 'client') and hasattr(crawler.client, 'search_videos_with_filters'):
                result = crawler.client.search_videos_with_filters(
                    keyword=keyword, 
                    page=page, 
                    sort=sort,
                    filter_type=filter_type,
                    include_cover=include_cover,
                    include_title=include_title,
                    max_results=max_results,
                    max_pages=max_pages,
                    enhanced_info=enhanced_info
                )
            else:
                # å›é€€åˆ°åŸæœ‰æœç´¢åŠŸèƒ½
                result = crawler.search_videos(
                    keyword=keyword, 
                    page=page, 
                    sort=sort,
                    include_cover=include_cover,
                    include_title=include_title,
                    max_results=max_results,
                    max_pages=max_pages
                )
            
            if result["success"]:
                results = result["results"]
                
                # æ„å»ºæ’åºè¯´æ˜
                sort_desc = ""
                if sort:
                    sort_names = {
                        'saved': 'æ”¶è—æ•°',
                        'today_views': 'æ—¥æµé‡',
                        'weekly_views': 'å‘¨æµé‡',
                        'monthly_views': 'æœˆæµé‡',
                        'views': 'æ€»æµé‡',
                        'updated': 'æœ€è¿‘æ›´æ–°',
                        'released_at': 'å‘è¡Œæ—¥æœŸ'
                    }
                    sort_desc = f"æ’åºæ–¹å¼: {sort_names.get(sort, sort)}\n"
                
                response_text = f"""### MissAV å¢å¼ºæœç´¢ç»“æœ ###

æœç´¢å…³é”®è¯: {keyword}
é¡µç èŒƒå›´: {page} - {page + max_pages - 1}
{sort_desc}æ‰¾åˆ°è§†é¢‘æ•°é‡: {result['total_count']}
å®é™…é¡µæ•°: {result.get('actual_pages', 1)}

"""
                
                if results:
                    response_text += "æœç´¢ç»“æœ:\n\n"
                    
                    for i, video in enumerate(results, 1):
                        response_text += f"{i}. **{video['title']}**\n"
                        response_text += f"   è§†é¢‘ä»£ç : {video['video_code']}\n"
                        response_text += f"   é“¾æ¥: {video['url']}\n"
                        
                        if include_cover and video.get('thumbnail'):
                            response_text += f"   å°é¢å›¾ç‰‡: {video['thumbnail']}\n"
                        
                        if include_title and video.get('full_title') and video.get('full_title') != video.get('title'):
                            response_text += f"   å®Œæ•´æ ‡é¢˜: {video['full_title']}\n"
                        
                        if video.get('publish_date'):
                            response_text += f"   å‘å¸ƒæ—¥æœŸ: {video['publish_date']}\n"
                        
                        if video.get('views'):
                            response_text += f"   è§‚çœ‹æ¬¡æ•°: {video['views']}\n"
                        
                        response_text += "\n"

                else:
                    response_text += "æœªæ‰¾åˆ°ç›¸å…³è§†é¢‘ã€‚\n"
                
                response_text += "\næœç´¢å®Œæˆï¼"
                
                return {
                    "status": "success",
                    "result": response_text
                }
            else:
                return {
                    "status": "error",
                    "error": result.get("error", "æœç´¢å¤±è´¥")
                }
        
        elif command == "GetHotVideos":
            category = request_data.get('category', 'daily') or 'daily'
            if isinstance(category, str):
                category = category.strip().lower()
            else:
                category = str(category).strip().lower() if category is not None else 'daily'
            
            # æ‰©å±•æœ‰æ•ˆåˆ†ç±»å‚æ•°ï¼ŒåŒ…æ‹¬æ–°çš„çœŸå®çƒ­æ¦œåˆ†ç±»
            valid_categories = [
                'daily', 'weekly', 'monthly', 'new', 'popular', 'trending',
                'chinese_subtitle', 'uncensored_leak', 'siro', 'luxu', 'gana'
            ]
            if category not in valid_categories:
                category = 'daily'
            
            page = request_data.get('page', 1)
            try:
                page = int(page) if page else 1
                if page < 1:
                    page = 1
            except (ValueError, TypeError):
                page = 1
            
            # å¤„ç†æ’åºå‚æ•°
            sort = request_data.get('sort', '').strip()
            valid_sorts = ['saved', 'today_views', 'weekly_views', 'monthly_views', 'views', 'updated', 'released_at']
            if sort and sort not in valid_sorts:
                sort = None
            
            # å¤„ç†è¿‡æ»¤å™¨å‚æ•°
            filter_type = request_data.get('filter', '').strip()
            valid_filters = ['all', 'single', 'japanese', 'uncensored_leak', 'uncensored', 'chinese_subtitle']
            if filter_type and filter_type not in valid_filters:
                filter_type = None
            
            # ä¼˜å…ˆä½¿ç”¨æ–°çš„çœŸå®çƒ­æ¦œåŠŸèƒ½
            result = None
            
            # å¦‚æœcrawlerå¯ç”¨ä¸”æœ‰æ–°çš„çƒ­æ¦œåŠŸèƒ½ï¼Œä½¿ç”¨å®ƒ
            if crawler and hasattr(crawler, 'client') and hasattr(crawler.client, 'get_hot_videos_with_filters'):
                try:
                    result = crawler.client.get_hot_videos_with_filters(category, page, sort, filter_type)
                except Exception as e:
                    print(f"æ–°çƒ­æ¦œåŠŸèƒ½å¤±è´¥: {str(e)}")
                    result = None
            
            # å¦‚æœæ–°åŠŸèƒ½ä¸å¯ç”¨ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨EnhancedHotVideos
            if result is None:
                try:
                    from missav_api_core.enhanced_hot_videos import EnhancedHotVideos
                    enhanced_hot = EnhancedHotVideos()
                    result = enhanced_hot.get_hot_videos_with_filters(category, page, sort, filter_type)
                except Exception as e:
                    print(f"ç›´æ¥ä½¿ç”¨EnhancedHotVideoså¤±è´¥: {str(e)}")
                    result = None
            
            # å¦‚æœæ‰€æœ‰æ–°åŠŸèƒ½éƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨æ—§çš„çƒ­æ¦œåŠŸèƒ½ä½œä¸ºæœ€åå¤‡ç”¨
            # ä¸å†ä½¿ç”¨è™šæ„æ•°æ®ä½œä¸ºå¤‡ç”¨æºï¼Œç›´æ¥è¿”å›çœŸå®ç»“æœ
            if result is None or not result.get("success"):
                return {
                    "status": "error",
                    "result": f"è·å–çƒ­æ¦œå¤±è´¥: æ— æ³•ä»çœŸå®æ•°æ®æºè·å– {category} çƒ­æ¦œæ•°æ®"
                }
            
            if result and result.get("success"):
                results = result["results"]
                category_name = {
                    'daily': 'æ¯æ—¥çƒ­é—¨',
                    'weekly': 'æ¯å‘¨çƒ­é—¨', 
                    'monthly': 'æ¯æœˆçƒ­é—¨',
                    'new': 'æœ€æ–°è§†é¢‘',
                    'popular': 'æœ€å—æ¬¢è¿',
                    'trending': 'è¶‹åŠ¿è§†é¢‘',
                    'chinese_subtitle': 'ä¸­æ–‡å­—å¹•',
                    'uncensored_leak': 'æ— ç æµå‡º',
                    'siro': 'SIROç³»åˆ—',
                    'luxu': 'LUXUç³»åˆ—',
                    'gana': 'GANAç³»åˆ—'
                }.get(category, 'çƒ­é—¨è§†é¢‘')
                
                response_text = f"""### MissAV {category_name} ###

åˆ†ç±»: {category_name}
é¡µç : {page}"""
                
                # æ·»åŠ æ•°æ®æºä¿¡æ¯
                if result.get("source"):
                    source_names = {
                        "real_crawl": "çœŸå®çˆ¬å–",
                        "fallback_with_filters": "å¤‡ç”¨æ•°æ®æº",
                        "generated_data": "æ¨¡æ‹Ÿæ•°æ®"
                    }
                    source_name = source_names.get(result["source"], result["source"])
                    response_text += f"\næ•°æ®æº: {source_name}"
                
                # æ·»åŠ æ’åºå’Œè¿‡æ»¤å™¨ä¿¡æ¯
                if result.get("applied_sort") or sort:
                    sort_names = {
                        'saved': 'æ”¶è—æ•°',
                        'today_views': 'æ—¥æµé‡',
                        'weekly_views': 'å‘¨æµé‡',
                        'monthly_views': 'æœˆæµé‡',
                        'views': 'æ€»æµé‡',
                        'updated': 'æœ€è¿‘æ›´æ–°',
                        'released_at': 'å‘è¡Œæ—¥æœŸ'
                    }
                    applied_sort = result.get("applied_sort") or sort
                    response_text += f"\næ’åºæ–¹å¼: {sort_names.get(applied_sort, applied_sort)}"
                
                if result.get("applied_filter") or filter_type:
                    filter_names = {
                        'all': 'æ‰€æœ‰',
                        'single': 'å–®äººä½œå“',
                        'japanese': 'æ—¥æœ¬AV',
                        'uncensored_leak': 'ç„¡ç¢¼æµå‡º',
                        'uncensored': 'ç„¡ç¢¼å½±ç‰‡',
                        'chinese_subtitle': 'ä¸­æ–‡å­—å¹•'
                    }
                    applied_filter = result.get("applied_filter") or filter_type
                    response_text += f"\nè¿‡æ»¤å™¨: {filter_names.get(applied_filter, applied_filter)}"
                
                response_text += f"\nè§†é¢‘æ•°é‡: {result['total_count']}\n\n"
                
                if results:
                    response_text += "çƒ­æ¦œè§†é¢‘:\n\n"
                    for i, video in enumerate(results, 1):
                        response_text += f"{i}. **{video['title']}**\n"
                        response_text += f"   è§†é¢‘ä»£ç : {video['video_code']}\n"
                        response_text += f"   é“¾æ¥: {video['url']}\n"
                        if video.get('thumbnail'):
                            response_text += f"   ç¼©ç•¥å›¾: {video['thumbnail']}\n"
                        if video.get('duration'):
                            response_text += f"   æ—¶é•¿: {video['duration']}\n"
                        if video.get('publish_date'):
                            response_text += f"   å‘å¸ƒæ—¥æœŸ: {video['publish_date']}\n"
                        response_text += "\n"

                else:
                    response_text += "æš‚æ— çƒ­æ¦œè§†é¢‘ã€‚\n"
                
                # æ·»åŠ æç¤ºä¿¡æ¯
                if result.get("note"):
                    response_text += f"\nğŸ’¡ {result['note']}\n"
                elif result.get("source") == "real_crawl":
                    response_text += f"\nâœ… æ•°æ®æ¥æºäºçœŸå®ç½‘ç«™çˆ¬å–\n"
                
                response_text += "\nçƒ­æ¦œè·å–å®Œæˆï¼"
                
                return {
                    "status": "success",
                    "result": response_text
                }
            else:
                error_msg = result.get("error", "è·å–çƒ­æ¦œå¤±è´¥") if result else "çƒ­æ¦œåŠŸèƒ½ä¸å¯ç”¨"
                return {
                    "status": "error",
                    "error": error_msg
                }
        
        elif command == "GetEnhancedVideoInfo":
            url = request_data.get('url', '') or ''
            if isinstance(url, str):
                url = url.strip()
            else:
                url = str(url).strip() if url is not None else ''
            if not url:
                return {
                    "status": "error",
                    "error": "ç¼ºå°‘ url å‚æ•°"
                }
            
            use_cache = request_data.get('use_cache', True)
            if isinstance(use_cache, str):
                use_cache = use_cache.lower() in ['true', '1', 'yes', 'on']
            
            # ä½¿ç”¨å¢å¼ºä¿¡æ¯æå–åŠŸèƒ½
            if hasattr(crawler, 'client') and hasattr(crawler.client, 'get_enhanced_video_info'):
                result = crawler.client.get_enhanced_video_info(url, use_cache)
            else:
                # å›é€€åˆ°åŸºç¡€ä¿¡æ¯è·å–
                result = crawler.get_video_info(url)
            
            if result.get("success"):
                # ä½¿ç”¨å¢å¼ºæ ¼å¼åŒ–å™¨
                if hasattr(crawler, 'client') and hasattr(crawler.client.info_extractor, 'format_info_response'):
                    response_text = crawler.client.info_extractor.format_info_response(result)
                else:
                    # åŸºç¡€æ ¼å¼åŒ–
                    info = result.get("info", result)
                    response_text = f"""### MissAV å¢å¼ºè§†é¢‘ä¿¡æ¯ ###

**æ ‡é¢˜**: {info.get('title', 'æœªçŸ¥')}
**è§†é¢‘ä»£ç **: {info.get('video_code', 'æœªçŸ¥')}
**å‘å¸ƒæ—¥æœŸ**: {info.get('publish_date', 'æœªçŸ¥')}
**æ—¶é•¿**: {info.get('duration', 'æœªçŸ¥')}
**ç¼©ç•¥å›¾**: {info.get('thumbnail', info.get('main_cover', 'æœªçŸ¥'))}
**åŸå§‹URL**: {url}

å¢å¼ºä¿¡æ¯è·å–æˆåŠŸï¼"""
                
                return {
                    "status": "success",
                    "result": response_text
                }
            else:
                return {
                    "status": "error",
                    "error": result.get("error", "è·å–å¢å¼ºè§†é¢‘ä¿¡æ¯å¤±è´¥")
                }
        
        elif command == "GetPreviewVideos":
            url = request_data.get('url', '') or ''
            if isinstance(url, str):
                url = url.strip()
            else:
                url = str(url).strip() if url is not None else ''
            if not url:
                return {
                    "status": "error",
                    "error": "ç¼ºå°‘ url å‚æ•°"
                }
            
            download = request_data.get('download', False)
            if isinstance(download, str):
                download = download.lower() in ['true', '1', 'yes', 'on']
            
            video_code = request_data.get('video_code', '').strip()
            output_dir = request_data.get('output_dir', '').strip()
            
            # ä½¿ç”¨é¢„è§ˆè§†é¢‘åŠŸèƒ½
            if hasattr(crawler, 'client') and hasattr(crawler.client, 'get_preview_videos'):
                result = crawler.client.get_preview_videos(
                    url, 
                    download=download, 
                    video_code=video_code if video_code else None,
                    output_dir=output_dir if output_dir else None
                )
                
                if result.get("success"):
                    # ä½¿ç”¨é¢„è§ˆä¸‹è½½å™¨çš„æ ¼å¼åŒ–å™¨
                    response_text = crawler.client.preview_downloader.format_preview_response(result)
                    
                    return {
                        "status": "success",
                        "result": response_text
                    }
                else:
                    return {
                        "status": "error",
                        "error": result.get("error", "é¢„è§ˆè§†é¢‘æ“ä½œå¤±è´¥")
                    }
            else:
                return {
                    "status": "error",
                    "error": "é¢„è§ˆè§†é¢‘åŠŸèƒ½ä¸å¯ç”¨"
                }
        
        elif command == "SearchWithFilters":
            # å¸¦è¿‡æ»¤å™¨çš„æœç´¢å‘½ä»¤
            keyword = request_data.get('keyword', '') or ''
            if isinstance(keyword, str):
                keyword = keyword.strip()
            else:
                keyword = str(keyword).strip() if keyword is not None else ''
            if not keyword:
                return {
                    "status": "error",
                    "error": "ç¼ºå°‘ keyword å‚æ•°"
                }
            
            # å¤„ç†æ‰€æœ‰å‚æ•°
            page = int(request_data.get('page', 1))
            sort = request_data.get('sort', '').strip()
            filter_type = request_data.get('filter', '').strip()
            include_cover = request_data.get('include_cover', True)
            include_title = request_data.get('include_title', True)
            max_results = int(request_data.get('max_results', 20))
            max_pages = int(request_data.get('max_pages', 1))
            
            # å¤„ç†å¢å¼ºä¿¡æ¯å‚æ•°
            enhanced_info = request_data.get('enhanced_info', False)
            if isinstance(enhanced_info, str):
                enhanced_info = enhanced_info.lower() in ['true', '1', 'yes', 'on']
            
            # ä½¿ç”¨å¢å¼ºæœç´¢åŠŸèƒ½
            if hasattr(crawler, 'client') and hasattr(crawler.client, 'search_videos_with_filters'):
                result = crawler.client.search_videos_with_filters(
                    keyword=keyword,
                    page=page,
                    sort=sort if sort else None,
                    filter_type=filter_type if filter_type else None,
                    include_cover=include_cover,
                    include_title=include_title,
                    max_results=max_results,
                    max_pages=max_pages,
                    enhanced_info=enhanced_info
                )
                
                if result.get("success"):
                    results = result["results"]
                    
                    # æ„å»ºå“åº”æ–‡æœ¬
                    response_text = f"""### MissAV å¢å¼ºæœç´¢ç»“æœ ###

æœç´¢å…³é”®è¯: {keyword}
é¡µç : {page}"""
                    
                    if result.get('sort_name'):
                        response_text += f"\næ’åºæ–¹å¼: {result['sort_name']}"
                    
                    if result.get('filter_name'):
                        response_text += f"\nè¿‡æ»¤å™¨: {result['filter_name']}"
                    
                    response_text += f"\næ‰¾åˆ°è§†é¢‘æ•°é‡: {result['total_count']}"
                    
                    if enhanced_info:
                        response_text += " (åŒ…å«å¢å¼ºä¿¡æ¯)"
                    
                    response_text += "\n\n"
                    
                    if results:
                        response_text += "æœç´¢ç»“æœ:\n\n"
                        for i, video in enumerate(results, 1):
                            response_text += f"{i}. **{video['title']}**\n"
                            response_text += f"   è§†é¢‘ä»£ç : {video['video_code']}\n"
                            response_text += f"   é“¾æ¥: {video['url']}\n"
                            
                            if include_cover and video.get('thumbnail'):
                                response_text += f"   å°é¢å›¾ç‰‡: {video['thumbnail']}\n"
                            
                            # æ˜¾ç¤ºå¢å¼ºä¿¡æ¯
                            if enhanced_info:
                                if video.get('actresses'):
                                    actresses = video['actresses']
                                    if isinstance(actresses, list):
                                        response_text += f"   æ¼”å‘˜: {', '.join(actresses[:3])}{'...' if len(actresses) > 3 else ''}\n"
                                    else:
                                        response_text += f"   æ¼”å‘˜: {actresses}\n"
                                
                                if video.get('tags'):
                                    tags = video['tags']
                                    if isinstance(tags, list):
                                        response_text += f"   ç±»å‹: {', '.join(tags[:5])}{'...' if len(tags) > 5 else ''}\n"
                                    else:
                                        response_text += f"   ç±»å‹: {tags}\n"
                                
                                if video.get('labels'):
                                    labels = video['labels']
                                    if isinstance(labels, list):
                                        response_text += f"   æ ‡ç­¾: {', '.join(labels)}\n"
                                    else:
                                        response_text += f"   æ ‡ç­¾: {labels}\n"
                                
                                if video.get('series'):
                                    response_text += f"   ç³»åˆ—: {video['series']}\n"
                                
                                if video.get('studio'):
                                    response_text += f"   å‘è¡Œå•†: {video['studio']}\n"
                                
                                if video.get('maker'):
                                    response_text += f"   åˆ¶ä½œå•†: {video['maker']}\n"
                                
                                if video.get('duration') or video.get('precise_duration'):
                                    duration = video.get('precise_duration') or video.get('duration')
                                    response_text += f"   æ—¶é•¿: {duration}\n"
                                
                                if video.get('release_date'):
                                    response_text += f"   å‘è¡Œæ—¥æœŸ: {video['release_date']}\n"
                                
                                # æ˜¾ç¤ºå¯ç”¨åˆ†è¾¨ç‡
                                if video.get('available_resolutions'):
                                    resolutions = video['available_resolutions']
                                    if isinstance(resolutions, list) and resolutions:
                                        res_count = len(resolutions)
                                        response_text += f"   å¯ç”¨åˆ†è¾¨ç‡ ({res_count}ä¸ª): "
                                        res_list = [f"{r['quality']} ({r['resolution']})" for r in resolutions[:4]]
                                        response_text += ", ".join(res_list)
                                        if len(resolutions) > 4:
                                            response_text += "..."
                                        response_text += "\n"
                                elif video.get('best_quality'):
                                    response_text += f"   æœ€é«˜ç”»è´¨: {video['best_quality']}\n"
                                
                                # æ˜¾ç¤ºé¢„è§ˆè§†é¢‘
                                if video.get('preview_videos'):
                                    previews = video['preview_videos']
                                    if isinstance(previews, list) and previews:
                                        response_text += f"   é¢„è§ˆè§†é¢‘: å¯ç”¨ ({len(previews)}ä¸ª)\n"
                                        response_text += f"     ä¸»é¢„è§ˆ: {previews[0]}\n"
                                
                                # æ˜¾ç¤ºM3U8æ’­æ”¾é“¾æ¥
                                if video.get('main_m3u8'):
                                    response_text += f"   M3U8æ’­æ”¾åˆ—è¡¨: {video['main_m3u8']}\n"
                                
                                if video.get('rating'):
                                    response_text += f"   è¯„åˆ†: {video['rating']}\n"
                                
                                if video.get('views') or video.get('view_count'):
                                    views = video.get('views') or video.get('view_count')
                                    response_text += f"   è§‚çœ‹æ¬¡æ•°: {views}\n"
                                
                                if video.get('description'):
                                    desc = video['description']
                                    # é€‚å½“é™åˆ¶æè¿°é•¿åº¦ï¼Œä½†ä¿ç•™æ›´å¤šå†…å®¹
                                    if len(desc) > 300:
                                        desc = desc[:300] + "..."
                                    response_text += f"   ç®€ä»‹: {desc}\n"
                            else:
                                # åŸºç¡€ä¿¡æ¯
                                if video.get('publish_date'):
                                    response_text += f"   å‘å¸ƒæ—¥æœŸ: {video['publish_date']}\n"
                            
                            response_text += "\n"

                    else:
                        response_text += "æœªæ‰¾åˆ°ç›¸å…³è§†é¢‘ã€‚\n"
                    
                    response_text += "\nå¢å¼ºæœç´¢å®Œæˆï¼"
                    
                    return {
                        "status": "success",
                        "result": response_text
                    }
                else:
                    return {
                        "status": "error",
                        "error": result.get("error", "å¢å¼ºæœç´¢å¤±è´¥")
                    }
            else:
                return {
                    "status": "error",
                    "error": "å¢å¼ºæœç´¢åŠŸèƒ½ä¸å¯ç”¨"
                }
        
        elif command == "GetHotWithFilters":
            # å¸¦è¿‡æ»¤å™¨çš„çƒ­æ¦œå‘½ä»¤ - ä¸SearchWithFiltersçœ‹é½
            category = request_data.get('category', 'daily') or 'daily'
            page = int(request_data.get('page', 1))
            sort = request_data.get('sort', '').strip()
            filter_type = request_data.get('filter', '').strip()
            include_cover = request_data.get('include_cover', True)
            include_title = request_data.get('include_title', True)
            max_results = int(request_data.get('max_results', 20))
            max_pages = int(request_data.get('max_pages', 1))
            
            # å¤„ç†å¢å¼ºä¿¡æ¯å‚æ•°
            enhanced_info = request_data.get('enhanced_info', False)
            if isinstance(enhanced_info, str):
                enhanced_info = enhanced_info.lower() in ['true', '1', 'yes', 'on']
            
            # ä½¿ç”¨å¢å¼ºçƒ­æ¦œåŠŸèƒ½
            if hasattr(crawler, 'client') and hasattr(crawler.client, 'get_hot_videos_with_filters'):
                result = crawler.client.get_hot_videos_with_filters(
                    category=category,
                    page=page,
                    sort=sort if sort else None,
                    filter_type=filter_type if filter_type else None,
                    include_cover=include_cover,
                    include_title=include_title,
                    max_results=max_results,
                    max_pages=max_pages,
                    enhanced_info=enhanced_info
                )
                
                if result.get("success"):
                    results = result["results"]
                    category_name = {
                        'daily': 'æ¯æ—¥çƒ­é—¨',
                        'weekly': 'æ¯å‘¨çƒ­é—¨', 
                        'monthly': 'æ¯æœˆçƒ­é—¨',
                        'new': 'æœ€æ–°è§†é¢‘',
                        'popular': 'æœ€å—æ¬¢è¿',
                        'trending': 'è¶‹åŠ¿è§†é¢‘'
                    }.get(category, 'çƒ­é—¨è§†é¢‘')
                    
                    response_text = f"""### MissAV {category_name} ###

åˆ†ç±»: {category_name}
é¡µç : {page}"""
                    
                    if result.get('sort_name'):
                        response_text += f"\næ’åºæ–¹å¼: {result['sort_name']}"
                    
                    if result.get('filter_name'):
                        response_text += f"\nè¿‡æ»¤å™¨: {result['filter_name']}"
                    
                    response_text += f"\næ‰¾åˆ°è§†é¢‘æ•°é‡: {result['total_count']}"
                    
                    if enhanced_info:
                        response_text += " (åŒ…å«å¢å¼ºä¿¡æ¯)"
                    
                    response_text += "\n\n"
                    
                    if results:
                        response_text += "çƒ­æ¦œè§†é¢‘:\n\n"
                        for i, video in enumerate(results, 1):
                            response_text += f"{i}. **{video['title']}**\n"
                            response_text += f"   è§†é¢‘ä»£ç : {video['video_code']}\n"
                            response_text += f"   é“¾æ¥: {video['url']}\n"
                            
                            if include_cover and video.get('thumbnail'):
                                response_text += f"   å°é¢å›¾ç‰‡: {video['thumbnail']}\n"
                            
                            # æ˜¾ç¤ºå¢å¼ºä¿¡æ¯
                            if enhanced_info:
                                if video.get('actresses'):
                                    actresses = video['actresses']
                                    if isinstance(actresses, list):
                                        response_text += f"   æ¼”å‘˜: {', '.join(actresses[:3])}{'...' if len(actresses) > 3 else ''}\n"
                                    else:
                                        response_text += f"   æ¼”å‘˜: {actresses}\n"
                                
                                if video.get('tags'):
                                    tags = video['tags']
                                    if isinstance(tags, list):
                                        response_text += f"   ç±»å‹: {', '.join(tags[:5])}{'...' if len(tags) > 5 else ''}\n"
                                    else:
                                        response_text += f"   ç±»å‹: {tags}\n"
                                
                                if video.get('labels'):
                                    labels = video['labels']
                                    if isinstance(labels, list):
                                        response_text += f"   æ ‡ç­¾: {', '.join(labels)}\n"
                                    else:
                                        response_text += f"   æ ‡ç­¾: {labels}\n"
                                
                                if video.get('series'):
                                    response_text += f"   ç³»åˆ—: {video['series']}\n"
                                
                                if video.get('studio'):
                                    response_text += f"   å‘è¡Œå•†: {video['studio']}\n"
                                
                                if video.get('maker'):
                                    response_text += f"   åˆ¶ä½œå•†: {video['maker']}\n"
                                
                                if video.get('duration') or video.get('precise_duration'):
                                    duration = video.get('precise_duration') or video.get('duration')
                                    response_text += f"   æ—¶é•¿: {duration}\n"
                                
                                if video.get('release_date'):
                                    response_text += f"   å‘è¡Œæ—¥æœŸ: {video['release_date']}\n"
                                
                                # æ˜¾ç¤ºå¯ç”¨åˆ†è¾¨ç‡
                                if video.get('available_resolutions'):
                                    resolutions = video['available_resolutions']
                                    if isinstance(resolutions, list) and resolutions:
                                        res_count = len(resolutions)
                                        response_text += f"   å¯ç”¨åˆ†è¾¨ç‡ ({res_count}ä¸ª): "
                                        res_list = [f"{r['quality']} ({r['resolution']})" for r in resolutions[:4]]
                                        response_text += ", ".join(res_list)
                                        if len(resolutions) > 4:
                                            response_text += "..."
                                        response_text += "\n"
                                elif video.get('best_quality'):
                                    response_text += f"   æœ€é«˜ç”»è´¨: {video['best_quality']}\n"
                                
                                # æ˜¾ç¤ºé¢„è§ˆè§†é¢‘
                                if video.get('preview_videos'):
                                    previews = video['preview_videos']
                                    if isinstance(previews, list) and previews:
                                        response_text += f"   é¢„è§ˆè§†é¢‘: å¯ç”¨ ({len(previews)}ä¸ª)\n"
                                        response_text += f"     ä¸»é¢„è§ˆ: {previews[0]}\n"
                                
                                # æ˜¾ç¤ºM3U8æ’­æ”¾é“¾æ¥
                                if video.get('main_m3u8'):
                                    response_text += f"   M3U8æ’­æ”¾åˆ—è¡¨: {video['main_m3u8']}\n"
                                
                                if video.get('rating'):
                                    response_text += f"   è¯„åˆ†: {video['rating']}\n"
                                
                                if video.get('views') or video.get('view_count'):
                                    views = video.get('views') or video.get('view_count')
                                    response_text += f"   è§‚çœ‹æ¬¡æ•°: {views}\n"
                                
                                if video.get('description'):
                                    desc = video['description']
                                    # é€‚å½“é™åˆ¶æè¿°é•¿åº¦ï¼Œä½†ä¿ç•™æ›´å¤šå†…å®¹
                                    if len(desc) > 300:
                                        desc = desc[:300] + "..."
                                    response_text += f"   ç®€ä»‹: {desc}\n"
                            else:
                                # åŸºç¡€ä¿¡æ¯
                                if video.get('duration'):
                                    response_text += f"   æ—¶é•¿: {video['duration']}\n"
                                if video.get('publish_date'):
                                    response_text += f"   å‘å¸ƒæ—¥æœŸ: {video['publish_date']}\n"
                            
                            response_text += "\n"

                    else:
                        response_text += "æš‚æ— çƒ­æ¦œè§†é¢‘ã€‚\n"
                    
                    if result.get("note"):
                        response_text += f"\nğŸ’¡ {result['note']}\n"
                    
                    response_text += "\nå¢å¼ºçƒ­æ¦œè·å–å®Œæˆï¼"
                    
                    return {
                        "status": "success",
                        "result": response_text
                    }
                else:
                    return {
                        "status": "error",
                        "error": result.get("error", "å¢å¼ºçƒ­æ¦œè·å–å¤±è´¥")
                    }
            else:
                return {
                    "status": "error",
                    "error": "å¢å¼ºçƒ­æ¦œåŠŸèƒ½ä¸å¯ç”¨"
                }
        
        else:
            return {
                "status": "error",
                "error": f"æœªçŸ¥å‘½ä»¤: {command}"
            }
    
    except Exception as e:
        return {
            "status": "error",
            "error": f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
            "traceback": traceback.format_exc()
        }


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¯»å–æ ‡å‡†è¾“å…¥
        input_data = sys.stdin.read().strip()
        
        if not input_data:
            result = {
                "status": "error",
                "error": "æ²¡æœ‰æ¥æ”¶åˆ°è¾“å…¥æ•°æ®"
            }
        else:
            try:
                # è§£æJSONè¾“å…¥
                request_data = json.loads(input_data)
                result = process_request(request_data)
            except json.JSONDecodeError as e:
                result = {
                    "status": "error",
                    "error": f"JSONè§£æå¤±è´¥: {str(e)}"
                }
    
    except Exception as e:
        result = {
            "status": "error",
            "error": f"æ’ä»¶æ‰§è¡Œå¤±è´¥: {str(e)}",
            "traceback": traceback.format_exc()
        }
    
    # è¾“å‡ºç»“æœ
    print(json.dumps(result, ensure_ascii=False), file=sys.stdout)
    sys.stdout.flush()


if __name__ == "__main__":
    main()