#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŸ¥æ‰¾cdnUrlå‡½æ•°çš„å®é™…å®ç°
"""

import sys
import re
import json
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å—
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from missav_api_core import MissAVCrawler

def find_cdn_function(url):
    """æŸ¥æ‰¾cdnUrlå‡½æ•°çš„å®é™…å®ç°"""
    print(f"ğŸ” æŸ¥æ‰¾cdnUrlå‡½æ•°å®ç°: {url}")
    print("=" * 80)
    
    # è·å–é¡µé¢å†…å®¹
    crawler = MissAVCrawler()
    extractor = crawler.client.info_extractor
    content = extractor.core.fetch(url)
    
    if not content:
        print("âŒ æ— æ³•è·å–é¡µé¢å†…å®¹")
        return
    
    print(f"âœ… é¡µé¢å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    print("-" * 80)
    
    # 1. æŸ¥æ‰¾æ‰€æœ‰åŒ…å«"cdn"çš„JavaScriptä»£ç 
    print("ğŸ“¥ æ­¥éª¤1: æŸ¥æ‰¾æ‰€æœ‰åŒ…å«'cdn'çš„ä»£ç ")
    
    # åˆ†å‰²é¡µé¢å†…å®¹ï¼ŒæŸ¥æ‰¾scriptæ ‡ç­¾
    script_pattern = r'<script[^>]*>(.*?)</script>'
    scripts = re.findall(script_pattern, content, re.DOTALL | re.IGNORECASE)
    
    print(f"æ‰¾åˆ° {len(scripts)} ä¸ªscriptæ ‡ç­¾")
    
    cdn_related_code = []
    
    for i, script in enumerate(scripts):
        if 'cdn' in script.lower() or 'doppiocdn' in script.lower():
            print(f"\nScript {i+1} åŒ…å«CDNç›¸å…³ä»£ç :")
            # æŸ¥æ‰¾å…·ä½“çš„CDNç›¸å…³è¡Œ
            lines = script.split('\n')
            for line_num, line in enumerate(lines, 1):
                if 'cdn' in line.lower() or 'doppiocdn' in line.lower():
                    clean_line = line.strip()
                    if clean_line and len(clean_line) > 10:  # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¡Œ
                        print(f"  è¡Œ{line_num}: {clean_line}")
                        cdn_related_code.append(clean_line)
    
    print("-" * 80)
    
    # 2. æŸ¥æ‰¾å…·ä½“çš„cdnUrlå‡½æ•°å®šä¹‰
    print("ğŸ“¥ æ­¥éª¤2: æŸ¥æ‰¾cdnUrlå‡½æ•°å®šä¹‰")
    
    # æ›´ç²¾ç¡®çš„å‡½æ•°å®šä¹‰æ¨¡å¼
    function_patterns = [
        r'function\s+cdnUrl\s*\([^)]*\)\s*{[^}]*}',
        r'cdnUrl\s*:\s*function\s*\([^)]*\)\s*{[^}]*}',
        r'cdnUrl\s*=\s*function\s*\([^)]*\)\s*{[^}]*}',
        r'const\s+cdnUrl\s*=\s*[^;]+',
        r'var\s+cdnUrl\s*=\s*[^;]+',
        r'let\s+cdnUrl\s*=\s*[^;]+',
        # ç®­å¤´å‡½æ•°
        r'cdnUrl\s*=\s*\([^)]*\)\s*=>\s*[^;]+',
        r'const\s+cdnUrl\s*=\s*\([^)]*\)\s*=>\s*[^;]+',
    ]
    
    found_functions = []
    
    for i, pattern in enumerate(function_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
        if matches:
            print(f"å‡½æ•°æ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches:
                clean_match = match.replace('\n', ' ').replace('\r', '')
                print(f"  - {clean_match}")
                found_functions.append(clean_match)
            print()
    
    # 3. æŸ¥æ‰¾CDNåŸºç¡€URLçš„å®šä¹‰
    print("ğŸ“¥ æ­¥éª¤3: æŸ¥æ‰¾CDNåŸºç¡€URLå®šä¹‰")
    
    cdn_base_patterns = [
        r'["\']https://[^"\']*doppiocdn[^"\']*["\']',
        r'["\']https://media[^"\']*\.net[^"\']*["\']',
        r'cdn[^=]*=\s*["\'][^"\']+["\']',
        r'baseUrl[^=]*=\s*["\'][^"\']+["\']',
        r'MEDIA_URL[^=]*=\s*["\'][^"\']+["\']',
    ]
    
    found_cdn_bases = []
    
    for i, pattern in enumerate(cdn_base_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            print(f"CDNåŸºç¡€URLæ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches[:5]:
                clean_match = match.strip('"\'')
                print(f"  - {clean_match}")
                if clean_match not in found_cdn_bases:
                    found_cdn_bases.append(clean_match)
            if len(matches) > 5:
                print(f"  ... è¿˜æœ‰ {len(matches) - 5} ä¸ª")
            print()
    
    # 4. æŸ¥æ‰¾Alpine.jsæˆ–Vue.jsçš„æ•°æ®ç»‘å®š
    print("ğŸ“¥ æ­¥éª¤4: æŸ¥æ‰¾Alpine.js/Vue.jsæ•°æ®ç»‘å®š")
    
    # æŸ¥æ‰¾x-dataæˆ–data()å®šä¹‰
    data_patterns = [
        r'x-data\s*=\s*["\'][^"\']*["\']',
        r'x-data\s*=\s*{[^}]*}',
        r'data\(\)\s*{[^}]*return\s*{[^}]*}[^}]*}',
    ]
    
    for i, pattern in enumerate(data_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
        if matches:
            print(f"æ•°æ®ç»‘å®šæ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches[:2]:
                clean_match = match.replace('\n', ' ')
                if len(clean_match) > 200:
                    clean_match = clean_match[:200] + "..."
                print(f"  - {clean_match}")
            print()
    
    # 5. æŸ¥æ‰¾windowå¯¹è±¡ä¸Šçš„å…¨å±€å˜é‡
    print("ğŸ“¥ æ­¥éª¤5: æŸ¥æ‰¾windowå¯¹è±¡ä¸Šçš„å…¨å±€å˜é‡")
    
    window_patterns = [
        r'window\.[^=\s]*[Cc]dn[^=\s]*\s*=\s*[^;]+',
        r'window\.[^=\s]*[Mm]edia[^=\s]*\s*=\s*[^;]+',
        r'window\.[^=\s]*[Bb]ase[^=\s]*\s*=\s*[^;]+',
    ]
    
    for i, pattern in enumerate(window_patterns, 1):
        matches = re.findall(pattern, content, re.IGNORECASE)
        if matches:
            print(f"Windowå˜é‡æ¨¡å¼{i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
            for match in matches:
                print(f"  - {match}")
            print()
    
    # 6. å°è¯•ä»å·²çŸ¥ä¿¡æ¯æ¨æ–­CDN URLæ„é€ é€»è¾‘
    print("ğŸ“¥ æ­¥éª¤6: æ¨æ–­CDN URLæ„é€ é€»è¾‘")
    
    # åŸºäºä½ æä¾›çš„ç¤ºä¾‹URLåˆ†æ
    example_url = "https://media-hls.doppiocdn.net/b-hls-06/117758835/117758835_240p_h264_501_FYTY49jYuOBbckr0_1754223961.mp4"
    print(f"ç¤ºä¾‹URL: {example_url}")
    
    # åˆ†æURLç»“æ„
    url_parts = example_url.split('/')
    print("URLç»“æ„åˆ†æ:")
    for i, part in enumerate(url_parts):
        print(f"  {i}: {part}")
    
    # æ¨æ–­å¯èƒ½çš„CDNåŸºç¡€URL
    possible_cdn_bases = [
        "https://media-hls.doppiocdn.net",
        "https://media-hls.doppiocdn.net/b-hls-06",
    ]
    
    print("\nå¯èƒ½çš„CDNåŸºç¡€URL:")
    for base in possible_cdn_bases:
        print(f"  - {base}")
    
    # æ„é€ é¢„è§ˆè§†é¢‘URLçš„å¯èƒ½æ¨¡å¼
    dvd_id = "jul-875"
    print(f"\nåŸºäºDVD ID '{dvd_id}' æ„é€ é¢„è§ˆè§†é¢‘URL:")
    
    for base in possible_cdn_bases:
        preview_urls = [
            f"{base}/{dvd_id}/preview.mp4",
            f"{base}/preview/{dvd_id}.mp4",
        ]
        
        for preview_url in preview_urls:
            print(f"  - {preview_url}")
    
    return found_functions, found_cdn_bases

def test_preview_urls():
    """æµ‹è¯•æ¨æ–­çš„é¢„è§ˆè§†é¢‘URL"""
    print("\nğŸ“¥ æµ‹è¯•æ¨æ–­çš„é¢„è§ˆè§†é¢‘URL")
    print("-" * 80)
    
    import requests
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://missav.ws/',
        'Accept': 'video/mp4,video/*,*/*;q=0.9',
        'Origin': 'https://missav.ws',
    }
    
    # åŸºäºåˆ†ææ„é€ çš„å¯èƒ½URL
    test_urls = [
        "https://media-hls.doppiocdn.net/jul-875/preview.mp4",
        "https://media-hls.doppiocdn.net/preview/jul-875.mp4",
        "https://media-hls.doppiocdn.net/b-hls-06/jul-875/preview.mp4",
        "https://media-hls.doppiocdn.net/b-hls-06/preview/jul-875.mp4",
    ]
    
    for i, test_url in enumerate(test_urls, 1):
        print(f"æµ‹è¯• {i}: {test_url}")
        
        try:
            response = requests.head(test_url, headers=headers, timeout=10)
            print(f"  çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                content_type = response.headers.get('Content-Type', '')
                content_length = response.headers.get('Content-Length', '')
                print(f"  å†…å®¹ç±»å‹: {content_type}")
                if content_length:
                    print(f"  æ–‡ä»¶å¤§å°: {content_length} å­—èŠ‚")
                print("  âœ… æˆåŠŸæ‰¾åˆ°é¢„è§ˆè§†é¢‘!")
                return test_url
            elif response.status_code == 403:
                print("  âš ï¸  403 Forbidden")
            elif response.status_code == 404:
                print("  âŒ 404 Not Found")
            else:
                print(f"  âŒ çŠ¶æ€ç : {response.status_code}")
                
        except Exception as e:
            print(f"  âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
        
        print()
    
    return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æŸ¥æ‰¾cdnUrlå‡½æ•°çš„å®é™…å®ç°")
    print("=" * 80)
    
    # æµ‹è¯•URL
    test_url = "https://missav.ws/dm44/jul-875"
    
    # æŸ¥æ‰¾CDNå‡½æ•°
    functions, cdn_bases = find_cdn_function(test_url)
    
    # æµ‹è¯•æ¨æ–­çš„URL
    success_url = test_preview_urls()
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ æŸ¥æ‰¾æ€»ç»“:")
    print(f"æ‰¾åˆ° {len(functions)} ä¸ªå¯èƒ½çš„cdnUrlå‡½æ•°")
    print(f"æ‰¾åˆ° {len(cdn_bases)} ä¸ªCDNåŸºç¡€URL")
    
    if success_url:
        print(f"âœ… æˆåŠŸæ‰¾åˆ°é¢„è§ˆè§†é¢‘URL: {success_url}")
    else:
        print("âŒ æœªæ‰¾åˆ°å¯è®¿é—®çš„é¢„è§ˆè§†é¢‘URL")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("1. éœ€è¦åˆ†æJavaScriptçš„æ‰§è¡Œé€»è¾‘")
    print("2. å¯èƒ½éœ€è¦æ¨¡æ‹Ÿæµè§ˆå™¨ç¯å¢ƒæ¥æ‰§è¡ŒcdnUrlå‡½æ•°")
    print("3. æˆ–è€…é€šè¿‡ç½‘ç»œæŠ“åŒ…æ¥è·å–å®é™…çš„é¢„è§ˆè§†é¢‘è¯·æ±‚")

if __name__ == "__main__":
    main()