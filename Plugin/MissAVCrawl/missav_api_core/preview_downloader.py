#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢„è§ˆè§†é¢‘ä¸‹è½½æ¨¡å—
æ”¯æŒä¸‹è½½è§†é¢‘çš„é¢„è§ˆå°è§†é¢‘ï¼ˆé¼ æ ‡æ‚¬åœæ—¶æ˜¾ç¤ºçš„å†…å®¹é€Ÿè§ˆè§†é¢‘ï¼‰
"""

import os
import re
import json
import time
import hashlib
import requests
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from urllib.parse import urljoin, urlparse


class PreviewDownloader:
    """é¢„è§ˆè§†é¢‘ä¸‹è½½å™¨"""
    
    def __init__(self, core=None, cache_dir: str = "./cache/previews"):
        self.core = core
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½é…ç½®
        self.download_timeout = 30
        self.max_retries = 3
        self.chunk_size = 8192
        
        # æ”¯æŒçš„é¢„è§ˆè§†é¢‘æ ¼å¼
        self.supported_formats = ['.mp4', '.webm', '.mov', '.avi']
        
        # é¢„è§ˆè§†é¢‘çš„å¸¸è§URLæ¨¡å¼
        self.preview_patterns = [
            r'"preview":\s*"([^"]*\.(?:mp4|webm|mov))"',
            r'"hover_video":\s*"([^"]*\.(?:mp4|webm|mov))"',
            r'"preview_video":\s*"([^"]*\.(?:mp4|webm|mov))"',
            r'data-preview="([^"]*\.(?:mp4|webm|mov))"',
            r'data-hover="([^"]*\.(?:mp4|webm|mov))"',
            r'preview[_-]?video[^"]*"([^"]*\.(?:mp4|webm|mov))"',
            r'hover[_-]?video[^"]*"([^"]*\.(?:mp4|webm|mov))"',
            r'onmouseover[^"]*"([^"]*\.(?:mp4|webm|mov))"',
        ]
    
    def extract_preview_urls(self, url: str, content: Optional[str] = None) -> Dict:
        """
        ä»è§†é¢‘é¡µé¢æå–é¢„è§ˆè§†é¢‘URL
        
        Args:
            url: è§†é¢‘é¡µé¢URL
            content: é¡µé¢å†…å®¹ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›ä¼šè‡ªåŠ¨è·å–ï¼‰
            
        Returns:
            åŒ…å«é¢„è§ˆè§†é¢‘URLçš„å­—å…¸
        """
        try:
            # è·å–é¡µé¢å†…å®¹
            if not content:
                if not self.core:
                    return {"success": False, "error": "æ ¸å¿ƒæ¨¡å—æœªåˆå§‹åŒ–ä¸”æœªæä¾›é¡µé¢å†…å®¹"}
                
                content = self.core.fetch(url)
                if not content:
                    return {"success": False, "error": "æ— æ³•è·å–é¡µé¢å†…å®¹"}
            
            preview_urls = []
            
            # ä½¿ç”¨å¤šç§æ¨¡å¼æå–é¢„è§ˆè§†é¢‘URL
            for pattern in self.preview_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    if match and match not in preview_urls:
                        # æ„å»ºå®Œæ•´URL
                        if match.startswith('http'):
                            preview_urls.append(match)
                        elif match.startswith('/'):
                            base_url = f"{urlparse(url).scheme}://{urlparse(url).netloc}"
                            preview_urls.append(urljoin(base_url, match))
                        else:
                            preview_urls.append(urljoin(url, match))
            
            # æŸ¥æ‰¾JavaScriptä¸­çš„é¢„è§ˆè§†é¢‘é…ç½®
            js_preview_urls = self._extract_js_preview_urls(content, url)
            preview_urls.extend(js_preview_urls)
            
            # æŸ¥æ‰¾CSSä¸­çš„é¢„è§ˆè§†é¢‘
            css_preview_urls = self._extract_css_preview_urls(content, url)
            preview_urls.extend(css_preview_urls)
            
            # å»é‡
            preview_urls = list(set(preview_urls))
            
            # éªŒè¯URLæœ‰æ•ˆæ€§
            valid_urls = []
            for preview_url in preview_urls:
                if self._is_valid_preview_url(preview_url):
                    valid_urls.append(preview_url)
            
            return {
                "success": True,
                "url": url,
                "preview_urls": valid_urls,
                "preview_count": len(valid_urls),
                "extraction_time": time.time()
            }
            
        except Exception as e:
            return {
                "success": False,
                "url": url,
                "error": f"æå–é¢„è§ˆè§†é¢‘URLå¤±è´¥: {str(e)}"
            }
    
    def _extract_js_preview_urls(self, content: str, base_url: str) -> List[str]:
        """ä»JavaScriptä»£ç ä¸­æå–é¢„è§ˆè§†é¢‘URL"""
        urls = []
        
        try:
            # æŸ¥æ‰¾JavaScriptå˜é‡ä¸­çš„é¢„è§ˆè§†é¢‘é…ç½®
            js_patterns = [
                r'var\s+preview\s*=\s*["\']([^"\']*\.(?:mp4|webm|mov))["\']',
                r'preview\s*:\s*["\']([^"\']*\.(?:mp4|webm|mov))["\']',
                r'hoverVideo\s*:\s*["\']([^"\']*\.(?:mp4|webm|mov))["\']',
                r'previewSrc\s*:\s*["\']([^"\']*\.(?:mp4|webm|mov))["\']',
            ]
            
            for pattern in js_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    if match.startswith('http'):
                        urls.append(match)
                    elif match.startswith('/'):
                        urls.append(urljoin(base_url, match))
            
            # æŸ¥æ‰¾JSONé…ç½®ä¸­çš„é¢„è§ˆè§†é¢‘
            json_patterns = [
                r'\{[^}]*"preview":\s*"([^"]*\.(?:mp4|webm|mov))"[^}]*\}',
                r'\{[^}]*"hover_video":\s*"([^"]*\.(?:mp4|webm|mov))"[^}]*\}',
            ]
            
            for pattern in json_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    if match.startswith('http'):
                        urls.append(match)
                    elif match.startswith('/'):
                        urls.append(urljoin(base_url, match))
            
        except Exception:
            pass
        
        return urls
    
    def _extract_css_preview_urls(self, content: str, base_url: str) -> List[str]:
        """ä»CSSæ ·å¼ä¸­æå–é¢„è§ˆè§†é¢‘URL"""
        urls = []
        
        try:
            # æŸ¥æ‰¾CSSä¸­çš„background-imageæˆ–contentå±æ€§ä¸­çš„è§†é¢‘URL
            css_patterns = [
                r'background-image:\s*url\(["\']?([^"\']*\.(?:mp4|webm|mov))["\']?\)',
                r'content:\s*url\(["\']?([^"\']*\.(?:mp4|webm|mov))["\']?\)',
            ]
            
            for pattern in css_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    if match.startswith('http'):
                        urls.append(match)
                    elif match.startswith('/'):
                        urls.append(urljoin(base_url, match))
            
        except Exception:
            pass
        
        return urls
    
    def _is_valid_preview_url(self, url: str) -> bool:
        """éªŒè¯é¢„è§ˆè§†é¢‘URLæ˜¯å¦æœ‰æ•ˆ"""
        try:
            # æ£€æŸ¥URLæ ¼å¼
            parsed = urlparse(url)
            if not parsed.scheme or not parsed.netloc:
                return False
            
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            path = parsed.path.lower()
            if not any(path.endswith(ext) for ext in self.supported_formats):
                return False
            
            # æ£€æŸ¥URLæ˜¯å¦åŒ…å«é¢„è§ˆç›¸å…³å…³é”®è¯
            preview_keywords = ['preview', 'hover', 'thumb', 'sample']
            url_lower = url.lower()
            if any(keyword in url_lower for keyword in preview_keywords):
                return True
            
            # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ç¬¦åˆé¢„è§ˆè§†é¢‘å‘½åè§„åˆ™
            filename = Path(parsed.path).name.lower()
            if any(keyword in filename for keyword in preview_keywords):
                return True
            
            return True  # é»˜è®¤è®¤ä¸ºæœ‰æ•ˆ
            
        except Exception:
            return False
    
    def download_preview_video(self, preview_url: str, video_code: str = None, 
                             output_dir: str = None, enable_cache: bool = True) -> Dict:
        """
        ä¸‹è½½é¢„è§ˆè§†é¢‘
        
        Args:
            preview_url: é¢„è§ˆè§†é¢‘URL
            video_code: è§†é¢‘ä»£ç ï¼ˆç”¨äºå‘½åï¼‰
            output_dir: è¾“å‡ºç›®å½•
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            
        Returns:
            ä¸‹è½½ç»“æœå­—å…¸
        """
        try:
            # è®¾ç½®è¾“å‡ºç›®å½•
            if not output_dir:
                output_dir = self.cache_dir / "preview_videos"
            else:
                output_dir = Path(output_dir)
            
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            if video_code:
                filename = f"{video_code}_preview"
            else:
                # ä»URLç”Ÿæˆæ–‡ä»¶å
                url_hash = hashlib.md5(preview_url.encode()).hexdigest()[:8]
                filename = f"preview_{url_hash}"
            
            # è·å–æ–‡ä»¶æ‰©å±•å
            parsed_url = urlparse(preview_url)
            ext = Path(parsed_url.path).suffix
            if not ext:
                ext = '.mp4'  # é»˜è®¤æ‰©å±•å
            
            output_file = output_dir / f"{filename}{ext}"
            
            # æ£€æŸ¥ç¼“å­˜
            if enable_cache and output_file.exists():
                file_size = output_file.stat().st_size
                if file_size > 1024:  # æ–‡ä»¶å¤§å°å¤§äº1KB
                    return {
                        "success": True,
                        "preview_url": preview_url,
                        "output_file": str(output_file),
                        "file_size": file_size,
                        "from_cache": True,
                        "message": "é¢„è§ˆè§†é¢‘å·²å­˜åœ¨äºç¼“å­˜ä¸­"
                    }
            
            # ä¸‹è½½é¢„è§ˆè§†é¢‘
            download_result = self._download_file(preview_url, output_file)
            
            if download_result["success"]:
                return {
                    "success": True,
                    "preview_url": preview_url,
                    "output_file": str(output_file),
                    "file_size": download_result["file_size"],
                    "download_time": download_result["download_time"],
                    "from_cache": False,
                    "message": "é¢„è§ˆè§†é¢‘ä¸‹è½½æˆåŠŸ"
                }
            else:
                return {
                    "success": False,
                    "preview_url": preview_url,
                    "error": download_result["error"]
                }
                
        except Exception as e:
            return {
                "success": False,
                "preview_url": preview_url,
                "error": f"ä¸‹è½½é¢„è§ˆè§†é¢‘å¤±è´¥: {str(e)}"
            }
    
    def _download_file(self, url: str, output_file: Path) -> Dict:
        """ä¸‹è½½æ–‡ä»¶çš„æ ¸å¿ƒæ–¹æ³•"""
        start_time = time.time()
        
        for attempt in range(self.max_retries):
            try:
                # è®¾ç½®è¯·æ±‚å¤´
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'video/mp4,video/webm,video/*,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.9',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Connection': 'keep-alive',
                }
                
                # å‘é€è¯·æ±‚
                response = requests.get(
                    url, 
                    headers=headers, 
                    timeout=self.download_timeout,
                    stream=True
                )
                response.raise_for_status()
                
                # æ£€æŸ¥å†…å®¹ç±»å‹
                content_type = response.headers.get('content-type', '').lower()
                if not any(video_type in content_type for video_type in ['video/', 'application/octet-stream']):
                    # å¦‚æœä¸æ˜¯è§†é¢‘ç±»å‹ï¼Œä½†æ–‡ä»¶æ‰©å±•åæ˜¯è§†é¢‘æ ¼å¼ï¼Œä»ç„¶å°è¯•ä¸‹è½½
                    if not any(url.lower().endswith(ext) for ext in self.supported_formats):
                        return {
                            "success": False,
                            "error": f"URLè¿”å›çš„ä¸æ˜¯è§†é¢‘å†…å®¹: {content_type}"
                        }
                
                # ä¸‹è½½æ–‡ä»¶
                total_size = 0
                with open(output_file, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=self.chunk_size):
                        if chunk:
                            f.write(chunk)
                            total_size += len(chunk)
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                if total_size < 1024:  # å°äº1KBå¯èƒ½æ˜¯é”™è¯¯é¡µé¢
                    output_file.unlink(missing_ok=True)
                    return {
                        "success": False,
                        "error": f"ä¸‹è½½çš„æ–‡ä»¶è¿‡å°: {total_size} bytes"
                    }
                
                download_time = time.time() - start_time
                
                return {
                    "success": True,
                    "file_size": total_size,
                    "download_time": download_time
                }
                
            except requests.exceptions.RequestException as e:
                if attempt < self.max_retries - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue
                else:
                    return {
                        "success": False,
                        "error": f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
                    }
            except Exception as e:
                return {
                    "success": False,
                    "error": f"ä¸‹è½½å¤±è´¥: {str(e)}"
                }
        
        return {
            "success": False,
            "error": "æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†"
        }
    
    def download_all_previews(self, url: str, video_code: str = None, 
                            output_dir: str = None, enable_cache: bool = True) -> Dict:
        """
        ä¸‹è½½è§†é¢‘çš„æ‰€æœ‰é¢„è§ˆè§†é¢‘
        
        Args:
            url: è§†é¢‘é¡µé¢URL
            video_code: è§†é¢‘ä»£ç 
            output_dir: è¾“å‡ºç›®å½•
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            
        Returns:
            ä¸‹è½½ç»“æœå­—å…¸
        """
        try:
            # æå–é¢„è§ˆè§†é¢‘URL
            extract_result = self.extract_preview_urls(url)
            
            if not extract_result["success"]:
                return extract_result
            
            preview_urls = extract_result["preview_urls"]
            
            if not preview_urls:
                return {
                    "success": True,
                    "url": url,
                    "message": "æœªæ‰¾åˆ°é¢„è§ˆè§†é¢‘",
                    "downloaded_count": 0,
                    "failed_count": 0,
                    "results": []
                }
            
            # ä¸‹è½½æ‰€æœ‰é¢„è§ˆè§†é¢‘
            results = []
            downloaded_count = 0
            failed_count = 0
            
            for i, preview_url in enumerate(preview_urls):
                # ä¸ºæ¯ä¸ªé¢„è§ˆè§†é¢‘ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
                if video_code:
                    current_video_code = f"{video_code}_{i+1}" if len(preview_urls) > 1 else video_code
                else:
                    current_video_code = f"preview_{i+1}"
                
                download_result = self.download_preview_video(
                    preview_url, 
                    current_video_code, 
                    output_dir, 
                    enable_cache
                )
                
                results.append(download_result)
                
                if download_result["success"]:
                    downloaded_count += 1
                else:
                    failed_count += 1
            
            return {
                "success": True,
                "url": url,
                "video_code": video_code,
                "preview_urls": preview_urls,
                "downloaded_count": downloaded_count,
                "failed_count": failed_count,
                "total_count": len(preview_urls),
                "results": results,
                "message": f"é¢„è§ˆè§†é¢‘ä¸‹è½½å®Œæˆ: æˆåŠŸ{downloaded_count}ä¸ªï¼Œå¤±è´¥{failed_count}ä¸ª"
            }
            
        except Exception as e:
            return {
                "success": False,
                "url": url,
                "error": f"æ‰¹é‡ä¸‹è½½é¢„è§ˆè§†é¢‘å¤±è´¥: {str(e)}"
            }
    
    def get_preview_info(self, url: str) -> Dict:
        """
        è·å–é¢„è§ˆè§†é¢‘ä¿¡æ¯ï¼ˆä¸ä¸‹è½½ï¼‰
        
        Args:
            url: è§†é¢‘é¡µé¢URL
            
        Returns:
            é¢„è§ˆè§†é¢‘ä¿¡æ¯å­—å…¸
        """
        try:
            # æå–é¢„è§ˆè§†é¢‘URL
            extract_result = self.extract_preview_urls(url)
            
            if not extract_result["success"]:
                return extract_result
            
            preview_urls = extract_result["preview_urls"]
            
            # è·å–æ¯ä¸ªé¢„è§ˆè§†é¢‘çš„è¯¦ç»†ä¿¡æ¯
            preview_info = []
            
            for preview_url in preview_urls:
                try:
                    # å‘é€HEADè¯·æ±‚è·å–æ–‡ä»¶ä¿¡æ¯
                    response = requests.head(preview_url, timeout=10)
                    
                    info = {
                        "url": preview_url,
                        "status_code": response.status_code,
                        "content_type": response.headers.get('content-type', ''),
                        "content_length": response.headers.get('content-length', ''),
                        "last_modified": response.headers.get('last-modified', ''),
                        "accessible": response.status_code == 200
                    }
                    
                    # ä¼°ç®—æ–‡ä»¶å¤§å°
                    if info["content_length"]:
                        try:
                            size_bytes = int(info["content_length"])
                            if size_bytes > 1024 * 1024:
                                info["file_size"] = f"{size_bytes / (1024 * 1024):.2f} MB"
                            elif size_bytes > 1024:
                                info["file_size"] = f"{size_bytes / 1024:.2f} KB"
                            else:
                                info["file_size"] = f"{size_bytes} bytes"
                        except ValueError:
                            info["file_size"] = "æœªçŸ¥"
                    else:
                        info["file_size"] = "æœªçŸ¥"
                    
                    preview_info.append(info)
                    
                except Exception as e:
                    preview_info.append({
                        "url": preview_url,
                        "error": str(e),
                        "accessible": False
                    })
            
            return {
                "success": True,
                "url": url,
                "preview_count": len(preview_urls),
                "preview_info": preview_info,
                "accessible_count": sum(1 for info in preview_info if info.get("accessible", False))
            }
            
        except Exception as e:
            return {
                "success": False,
                "url": url,
                "error": f"è·å–é¢„è§ˆè§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}"
            }
    
    def format_preview_response(self, result: Dict) -> str:
        """æ ¼å¼åŒ–é¢„è§ˆè§†é¢‘å“åº”ä¸ºæ–‡æœ¬"""
        if not result.get("success"):
            return f"é¢„è§ˆè§†é¢‘æ“ä½œå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        response_text = "### MissAV é¢„è§ˆè§†é¢‘ä¿¡æ¯ ###\n\n"
        
        if "downloaded_count" in result:
            # ä¸‹è½½ç»“æœ
            response_text += f"**è§†é¢‘URL**: {result.get('url', '')}\n"
            if result.get('video_code'):
                response_text += f"**è§†é¢‘ä»£ç **: {result['video_code']}\n"
            
            response_text += f"**é¢„è§ˆè§†é¢‘æ•°é‡**: {result.get('total_count', 0)}\n"
            response_text += f"**ä¸‹è½½æˆåŠŸ**: {result.get('downloaded_count', 0)}\n"
            response_text += f"**ä¸‹è½½å¤±è´¥**: {result.get('failed_count', 0)}\n\n"
            
            if result.get('results'):
                response_text += "**ä¸‹è½½è¯¦æƒ…**:\n"
                for i, download_result in enumerate(result['results'], 1):
                    if download_result.get('success'):
                        file_size = download_result.get('file_size', 0)
                        size_mb = file_size / (1024 * 1024) if file_size > 0 else 0
                        cache_status = " (ç¼“å­˜)" if download_result.get('from_cache') else ""
                        response_text += f"  {i}. âœ… {Path(download_result['output_file']).name} ({size_mb:.2f}MB){cache_status}\n"
                    else:
                        response_text += f"  {i}. âŒ ä¸‹è½½å¤±è´¥: {download_result.get('error', 'æœªçŸ¥é”™è¯¯')}\n"
        
        elif "preview_info" in result:
            # ä¿¡æ¯æŸ¥è¯¢ç»“æœ
            response_text += f"**è§†é¢‘URL**: {result.get('url', '')}\n"
            response_text += f"**é¢„è§ˆè§†é¢‘æ•°é‡**: {result.get('preview_count', 0)}\n"
            response_text += f"**å¯è®¿é—®æ•°é‡**: {result.get('accessible_count', 0)}\n\n"
            
            if result.get('preview_info'):
                response_text += "**é¢„è§ˆè§†é¢‘è¯¦æƒ…**:\n"
                for i, info in enumerate(result['preview_info'], 1):
                    if info.get('accessible'):
                        response_text += f"  {i}. âœ… {info.get('file_size', 'æœªçŸ¥å¤§å°')} - {info['url']}\n"
                        if info.get('content_type'):
                            response_text += f"      ç±»å‹: {info['content_type']}\n"
                    else:
                        response_text += f"  {i}. âŒ ä¸å¯è®¿é—® - {info['url']}\n"
                        if info.get('error'):
                            response_text += f"      é”™è¯¯: {info['error']}\n"
        
        else:
            # åŸºç¡€æå–ç»“æœ
            response_text += f"**è§†é¢‘URL**: {result.get('url', '')}\n"
            response_text += f"**é¢„è§ˆè§†é¢‘æ•°é‡**: {result.get('preview_count', 0)}\n\n"
            
            if result.get('preview_urls'):
                response_text += "**é¢„è§ˆè§†é¢‘URL**:\n"
                for i, url in enumerate(result['preview_urls'], 1):
                    response_text += f"  {i}. {url}\n"
        
        response_text += f"\n{result.get('message', 'æ“ä½œå®Œæˆ')}"
        
        return response_text


def test_preview_downloader():
    """æµ‹è¯•é¢„è§ˆè§†é¢‘ä¸‹è½½å™¨"""
    print("ğŸ¬ æµ‹è¯•é¢„è§ˆè§†é¢‘ä¸‹è½½å™¨")
    print("=" * 50)
    
    downloader = PreviewDownloader()
    
    # æµ‹è¯•URLæ¨¡å¼åŒ¹é…
    test_content = '''
    <script>
    var preview = "https://example.com/preview.mp4";
    var hoverVideo = "/videos/hover_video.webm";
    </script>
    <div data-preview="https://example.com/sample.mp4"></div>
    '''
    
    result = downloader.extract_preview_urls("https://example.com/video", test_content)
    print("URLæå–æµ‹è¯•:")
    print(f"  æˆåŠŸ: {result['success']}")
    print(f"  æ‰¾åˆ°URLæ•°é‡: {result.get('preview_count', 0)}")
    if result.get('preview_urls'):
        for url in result['preview_urls']:
            print(f"    - {url}")
    
    print("\nâœ… é¢„è§ˆè§†é¢‘ä¸‹è½½å™¨æ¨¡å—å·²åˆ›å»º")


if __name__ == "__main__":
    test_preview_downloader()